# -*- coding: utf-8 -*-
"""KNN e Regressão logistica.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1zPK6JRwSPUEskRbHoos4F13qqw0_1YqR

## Dados

### Importação
"""

import pandas as pd

dados = pd.read_csv('/content/drive/MyDrive/Regressao_Linear/winequality-red.csv', delimiter=';')

dados.head()

dados['alcohol'] = dados['alcohol'].astype(float) #Mudando o tipo da coluna string para float. Para poder trabalhar com a informação

dados.info()

"""### Separando as observações do target"""

x = dados[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']]

y = dados['quality']

x.shape

y.shape

"""### Análise Exploratoria"""

import seaborn as sns

sns.pairplot(dados,x_vars=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol'], y_vars='quality', size=4, kind='reg')

"""*Usando os graficos acima para poder visualizar quais observações/Variaveis tem maior e menos relação com o resultado alvo, o "target" quality*"""

import numpy as np

x_var = dados[['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']].values

y_var = dados['quality'].values

correlacao = np.corrcoef(x_var.T, y_var)
correlacao

"""*"corrcoef" é usado para verificar a correlação de cada observação com o resultado.*"""

sns.heatmap(correlacao, yticklabels=['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol','quality'],annot=True)

"""*Passando a variavel que guarda as informações da correlação para o grafico acima, conseguimor observalor melhor a correlação de cada observação com o resultado "quality". E o nivel de correlação*

### Separação dos dados para treino e teste
"""

from sklearn.model_selection import train_test_split

x = dados[['fixed acidity','citric acid','sulphates','alcohol']] #Pela a analise exploratoria, vimos que somente essas observações são as mais relevantes para constuir nosso modelo. Por isso definimos novamente o eixo x

x_treino, x_teste, y_treino, y_teste = train_test_split(x,y,test_size=0.30)

"""# KNN (k-nearest neighbors algorithm)"""

from sklearn.neighbors import KNeighborsClassifier
from sklearn import metrics

valores = {}
k = 1
vencedor = []

while k <= 25:
  knn = KNeighborsClassifier(n_neighbors=k)
  knn.fit(x_treino,y_treino)
  previsao_knn = knn.predict(x_teste)
  acertos_knn = metrics.accuracy_score(y_teste,previsao_knn)
  valores[k] = round(acertos_knn,4)
  k += 1

print(valores)
valor_k = max(valores, key=valores.get)
print("Valor do k é ",valor_k," e porcentagem de acertos",valores[valor_k])

"""*Acima foi feito um Loop, para descobrir qual é o melhor valor do "K" e a porcentagem de acerto do modelo usando esse "K". Imprimindo o resultado*

# Regressao Logistica
"""

from sklearn.linear_model import LogisticRegression

logred = LogisticRegression()

logred.fit(x_treino,y_treino)

previsao_logreg = logred.predict(x_teste)

logred.predict([[11.2,0.00,0.58,9.8]])

acertos_logreg = metrics.accuracy_score(y_teste,previsao_logreg)
acertos_logreg

"""*Acima mostra a porcetagem de acerto do nosso Modelo. Usando a Regressão Logistica*

# **Observação!**
"""

valores[valor_k] #KNN

acertos_logreg #Regressão Logistica

"""*Acima conseguimos ver a porcentagem de acerto usando o KNN e o outro usando a Regressão Logistica. A que tiver mais porcentagem de acerto, é a melhor para usarmos para analisarmos os dados*"""